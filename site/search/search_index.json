{
  "config": {
    "lang": [
      "en"
    ],
    "prebuild_index": false,
    "separator": "[\\s\\-]+"
  },
  "docs": [
    {
      "location": "",
      "text": "Makisu is a fast and flexible Docker image build tool designed for unprivileged containerized environments such as Mesos or Kubernetes. Some highlights of makisu: * Requires no elevated privileges or containerd/Docker daemon, making the build process portable. * Uses a distributed layer cache to improve performance across a build cluster. * Provides control over generated layers with a new optional keyword #!COMMIT , reducing the number of layers in images. * Is Docker compatible. Note, the Dockerfile parser in Makisu is opinionated in some scenarios. More details can be found here . Makisu has been in use at Uber since early 2018, building thousands of images every day across 4 different languages. The motivation and mechanism behind it are explained in https://eng.uber.com/makisu/. Building Makisu Running Makisu Makisu anywhere Makisu on Kubernetes Using Cache Configuring distributed cache Explicit Commit and Cache Configuring Docker Registry Comparison With Similar Tools Contributing Contact Building Makisu Building Makisu image To build a Docker image that can perform builds inside a container: make images Building Makisu binary and build simple images To get the makisu binary locally: go get github.com/uber/makisu/bin/makisu For a Dockerfile that doesn't have RUN, makisu can build it without Docker daemon, containerd or runc: makisu build -t ${TAG} --dest ${TAR_PATH} ${CONTEXT} Running Makisu For a full list of flags, run makisu build --help or refer to the README here . Makisu anywhere To build Dockerfiles that contain RUN, Makisu needs to run in a container. To try it locally, the following snippet can be placed inside your ~/.bashrc or ~/.zshrc : function makisu_build() { makisu_version=${MAKISU_VERSION:-latest} cd ${@: -1} docker run -i --rm --net host \\ -v /var/run/docker.sock:/docker.sock \\ -e DOCKER_HOST=unix:///docker.sock \\ -v $(pwd):/makisu-context \\ -v /tmp/makisu-storage:/makisu-storage \\ gcr.io/uber-container-tools/makisu:$makisu_version build \\ --commit=explicit \\ --modifyfs=true \\ --load \\ ${@:1:${#@}-1} /makisu-context cd - } Now you can use makisu_build like you would use docker build : $ makisu_build -t myimage . Note: * Docker socket mount is optional. It's used together with --load for loading images back into Docker daemon for convenience of local development. So does the mount to /makisu-storage, which is used for local cache. If the image would be pushed to registry directly, please remove --load for better performance. * The --modifyfs-true option let Makisu assume ownership of the filesystem inside the container. Files in the container that don't belong to the base image will be overwritten at the beginning of build. * The --commit=explicit option let Makisu only commit layer when it sees #COMMIT and at the end of the Dockerfile. See \"Explicit Commit and Cache\" for more details. Makisu on Kubernetes Makisu makes it easy to build images from a GitHub repository inside Kubernetes. A single pod (or job) is created with an init container, which will fetch the build context through git or other means, and place that context in a designated volume. Once it completes, the Makisu container will be created and executes the build, using that volume as its build context. Creating registry configuration Makisu needs registry configuration mounted in to push to a secure registry. The config format is described in documentation . After creating configuration file on local filesystem, run the following command to create the k8s secret: $ kubectl create secret generic docker-registry-config --from-file=./registry.yaml secret/docker-registry-config created Creating Kubernetes job spec To setup a Kubernetes job to build a GitHub repository and push to a secure registry, you can refer to our Kubernetes job spec template (and out of the box example ) . With such a job spec, a simple kubectl create -f job.yaml will start the build. The job status will reflect whether the build succeeded or failed Using cache Configuring distributed cache Makisu supports distributed cache, which can significantly reduce build time, by up to 90% for some of Uber's code repos. Makisu caches docker image layers both locally and in docker registry (if --push parameter is provided), and uses a separate key-value store to map lines of a Dockerfile to names of the layers. For example, Redis can be setup as a distributed cache key-value store with this Kubernetes job spec . Then connect Makisu to redis cache by passing --redis-cache-addr=redis:6379 argument. If the Redis server is password-protected, use --redis-cache-password=password argument. Cache has a 7 day TTL by default, which can be configured with --local-cache-ttl=7d argument. For more options on cache, please see Cache . Explicit commit and cache By default, Makisu will cache each directive in a Dockerfile. To avoid committing and caching everything, the layer cache can be further optimized via explicit caching with the --commit=explicit flag. Dockerfile directives may then be manually cached using the #!COMMIT annotation: FROM node:8.1.3 ADD package.json package.json ADD pre-build.sh # A bunch of pre-install steps here. ... ... ... # A step to be cached. A single layer will be committed and cached here on top of base image. RUN npm install #!COMMIT ... ... ... # The last step of the last stage always commit by default, generating and caching another layer. ENTRYPOINT [\"/bin/bash\"] In this example, only 2 additional layers on top of base image will be generated and cached. Configuring Docker Registry For the convenience to work with any public Docker Hub repositories including library/.*, a default config is provided: index.docker.io: .*: security: tls: client: disabled: false // Docker Hub requires basic auth with empty username and password for all public repositories. basic: username: \"\" password: \"\" Registry configs can be passed in through the --registry-config flag, either as a file path of as a raw json blob (converted to json using yq ): --registry-config='{\"gcr.io\": {\"uber-container-tools/*\": {\"push_chunk\": -1, \"security\": {\"basic\": {\"username\": \"_json_key\", \"password\": \"<escaped key here>\"}}}}}' For more details on configuring Makisu to work with your registry client, see the documentation . Comparison With Similar Tools Bazel We were inspired by the Bazel project in early 2017. It is one of the first few tools that could build Docker compatible images without using Docker or any form of containerizer. It works very well with a subset of Docker build scenarios given a Bazel build file. However, it does not support RUN , making it hard to replace most docker build workflows. Kaniko Kaniko provides good compatibility with Docker and executes build commands in userspace without the need for Docker daemon, although it must still run inside a container. Kaniko offers smooth integration with Kubernetes, making it a competent tool for Kubernetes users. On the other hand, Makisu has some performance tweaks for large images (especially those with node_modules), allows cache to expire, and offers more control over cache generation through #!COMMIT, make it optimal for complex workflows. BuildKit / img BuildKit and img depend on runc/containerd and supports parallel stage executions, whereas Makisu and most other tools execute Dockefile in order. However, BuildKit and img still need seccomp and AppArmor to be disabled to launch nested containers, which is not ideal and may not be doable in some production environments. Contributing Please check out our guide . Contact To contact us, please join our Slack channel .",
      "title": "Home"
    },
    {
      "location": "#building-makisu",
      "text": "",
      "title": "Building Makisu"
    },
    {
      "location": "#building-makisu-image",
      "text": "To build a Docker image that can perform builds inside a container: make images",
      "title": "Building Makisu image"
    },
    {
      "location": "#building-makisu-binary-and-build-simple-images",
      "text": "To get the makisu binary locally: go get github.com/uber/makisu/bin/makisu For a Dockerfile that doesn't have RUN, makisu can build it without Docker daemon, containerd or runc: makisu build -t ${TAG} --dest ${TAR_PATH} ${CONTEXT}",
      "title": "Building Makisu binary and build simple images"
    },
    {
      "location": "#running-makisu",
      "text": "For a full list of flags, run makisu build --help or refer to the README here .",
      "title": "Running Makisu"
    },
    {
      "location": "#makisu-anywhere",
      "text": "To build Dockerfiles that contain RUN, Makisu needs to run in a container. To try it locally, the following snippet can be placed inside your ~/.bashrc or ~/.zshrc : function makisu_build() { makisu_version=${MAKISU_VERSION:-latest} cd ${@: -1} docker run -i --rm --net host \\ -v /var/run/docker.sock:/docker.sock \\ -e DOCKER_HOST=unix:///docker.sock \\ -v $(pwd):/makisu-context \\ -v /tmp/makisu-storage:/makisu-storage \\ gcr.io/uber-container-tools/makisu:$makisu_version build \\ --commit=explicit \\ --modifyfs=true \\ --load \\ ${@:1:${#@}-1} /makisu-context cd - } Now you can use makisu_build like you would use docker build : $ makisu_build -t myimage . Note: * Docker socket mount is optional. It's used together with --load for loading images back into Docker daemon for convenience of local development. So does the mount to /makisu-storage, which is used for local cache. If the image would be pushed to registry directly, please remove --load for better performance. * The --modifyfs-true option let Makisu assume ownership of the filesystem inside the container. Files in the container that don't belong to the base image will be overwritten at the beginning of build. * The --commit=explicit option let Makisu only commit layer when it sees #COMMIT and at the end of the Dockerfile. See \"Explicit Commit and Cache\" for more details.",
      "title": "Makisu anywhere"
    },
    {
      "location": "#makisu-on-kubernetes",
      "text": "Makisu makes it easy to build images from a GitHub repository inside Kubernetes. A single pod (or job) is created with an init container, which will fetch the build context through git or other means, and place that context in a designated volume. Once it completes, the Makisu container will be created and executes the build, using that volume as its build context.",
      "title": "Makisu on Kubernetes"
    },
    {
      "location": "#creating-registry-configuration",
      "text": "Makisu needs registry configuration mounted in to push to a secure registry. The config format is described in documentation . After creating configuration file on local filesystem, run the following command to create the k8s secret: $ kubectl create secret generic docker-registry-config --from-file=./registry.yaml secret/docker-registry-config created",
      "title": "Creating registry configuration"
    },
    {
      "location": "#creating-kubernetes-job-spec",
      "text": "To setup a Kubernetes job to build a GitHub repository and push to a secure registry, you can refer to our Kubernetes job spec template (and out of the box example ) . With such a job spec, a simple kubectl create -f job.yaml will start the build. The job status will reflect whether the build succeeded or failed",
      "title": "Creating Kubernetes job spec"
    },
    {
      "location": "#using-cache",
      "text": "",
      "title": "Using cache"
    },
    {
      "location": "#configuring-distributed-cache",
      "text": "Makisu supports distributed cache, which can significantly reduce build time, by up to 90% for some of Uber's code repos. Makisu caches docker image layers both locally and in docker registry (if --push parameter is provided), and uses a separate key-value store to map lines of a Dockerfile to names of the layers. For example, Redis can be setup as a distributed cache key-value store with this Kubernetes job spec . Then connect Makisu to redis cache by passing --redis-cache-addr=redis:6379 argument. If the Redis server is password-protected, use --redis-cache-password=password argument. Cache has a 7 day TTL by default, which can be configured with --local-cache-ttl=7d argument. For more options on cache, please see Cache .",
      "title": "Configuring distributed cache"
    },
    {
      "location": "#explicit-commit-and-cache",
      "text": "By default, Makisu will cache each directive in a Dockerfile. To avoid committing and caching everything, the layer cache can be further optimized via explicit caching with the --commit=explicit flag. Dockerfile directives may then be manually cached using the #!COMMIT annotation: FROM node:8.1.3 ADD package.json package.json ADD pre-build.sh # A bunch of pre-install steps here. ... ... ... # A step to be cached. A single layer will be committed and cached here on top of base image. RUN npm install #!COMMIT ... ... ... # The last step of the last stage always commit by default, generating and caching another layer. ENTRYPOINT [\"/bin/bash\"] In this example, only 2 additional layers on top of base image will be generated and cached.",
      "title": "Explicit commit and cache"
    },
    {
      "location": "#configuring-docker-registry",
      "text": "For the convenience to work with any public Docker Hub repositories including library/.*, a default config is provided: index.docker.io: .*: security: tls: client: disabled: false // Docker Hub requires basic auth with empty username and password for all public repositories. basic: username: \"\" password: \"\" Registry configs can be passed in through the --registry-config flag, either as a file path of as a raw json blob (converted to json using yq ): --registry-config='{\"gcr.io\": {\"uber-container-tools/*\": {\"push_chunk\": -1, \"security\": {\"basic\": {\"username\": \"_json_key\", \"password\": \"<escaped key here>\"}}}}}' For more details on configuring Makisu to work with your registry client, see the documentation .",
      "title": "Configuring Docker Registry"
    },
    {
      "location": "#comparison-with-similar-tools",
      "text": "",
      "title": "Comparison With Similar Tools"
    },
    {
      "location": "#bazel",
      "text": "We were inspired by the Bazel project in early 2017. It is one of the first few tools that could build Docker compatible images without using Docker or any form of containerizer. It works very well with a subset of Docker build scenarios given a Bazel build file. However, it does not support RUN , making it hard to replace most docker build workflows.",
      "title": "Bazel"
    },
    {
      "location": "#kaniko",
      "text": "Kaniko provides good compatibility with Docker and executes build commands in userspace without the need for Docker daemon, although it must still run inside a container. Kaniko offers smooth integration with Kubernetes, making it a competent tool for Kubernetes users. On the other hand, Makisu has some performance tweaks for large images (especially those with node_modules), allows cache to expire, and offers more control over cache generation through #!COMMIT, make it optimal for complex workflows.",
      "title": "Kaniko"
    },
    {
      "location": "#buildkit-img",
      "text": "BuildKit and img depend on runc/containerd and supports parallel stage executions, whereas Makisu and most other tools execute Dockefile in order. However, BuildKit and img still need seccomp and AppArmor to be disabled to launch nested containers, which is not ideal and may not be doable in some production environments.",
      "title": "BuildKit / img"
    },
    {
      "location": "#contributing",
      "text": "Please check out our guide .",
      "title": "Contributing"
    },
    {
      "location": "#contact",
      "text": "To contact us, please join our Slack channel .",
      "title": "Contact"
    },
    {
      "location": "CACHE/",
      "text": "Cache Configuration Makisu supports distributed cache, which can significantly reduce build time, by up to 90% for some of Uber's code repos. Makisu caches docker image layers both locally and in docker registry (if --push parameter is provided). It uses a separate key-value store to map lines of a Dockerfile to names of the layers. For cache key-value store, Makisu supports 3 choices: local file cache, redis based distributed cache, and generic HTTP based distributed cache. Local file cache If no cache options are provided, local file cache is used by default. To configure local file cache TTL: --local-cache-ttl duration Time-To-Live for local cache (default 168h0m0s) To disable it, set ttl to 0s. Redis cache To configure redis cache, use the following options: --redis-cache-addr string The address of a redis server for cacheID to layer sha mapping --redis-cache-password string The password of the Redis server, should match 'requirepass' in redis.conf --redis-cache-ttl duration Time-To-Live for redis cache (default 168h0m0s) HTTP cache To configure HTTP cache, use the following options: --http-cache-addr string The address of the http server for cacheID to layer sha mapping --http-cache-header stringArray Request header for http cache server. Format is \"--http-cache-header <header>:<value>\" Explicit commit and cache By default, Makisu will cache each directive in a Dockerfile. To avoid committing and caching everything, the layer cache can be further optimized via explicit caching with the --commit=explicit flag. Dockerfile directives may then be manually cached using the #!COMMIT annotation: FROM node:8.1.3 ADD package.json package.json ADD pre-build.sh # A bunch of pre-install steps here. ... ... ... # A step to be cached. A single layer will be committed and cached here on top of base image. RUN npm install #!COMMIT ... ... ... # The last step of the last stage always commit by default, generating and caching another layer. ENTRYPOINT [\"/bin/bash\"] In this example, only 2 additional layers on top of base image will be generated and cached.",
      "title": "Cache Configuration"
    },
    {
      "location": "CACHE/#cache-configuration",
      "text": "Makisu supports distributed cache, which can significantly reduce build time, by up to 90% for some of Uber's code repos. Makisu caches docker image layers both locally and in docker registry (if --push parameter is provided). It uses a separate key-value store to map lines of a Dockerfile to names of the layers. For cache key-value store, Makisu supports 3 choices: local file cache, redis based distributed cache, and generic HTTP based distributed cache.",
      "title": "Cache Configuration"
    },
    {
      "location": "CACHE/#local-file-cache",
      "text": "If no cache options are provided, local file cache is used by default. To configure local file cache TTL: --local-cache-ttl duration Time-To-Live for local cache (default 168h0m0s) To disable it, set ttl to 0s.",
      "title": "Local file cache"
    },
    {
      "location": "CACHE/#redis-cache",
      "text": "To configure redis cache, use the following options: --redis-cache-addr string The address of a redis server for cacheID to layer sha mapping --redis-cache-password string The password of the Redis server, should match 'requirepass' in redis.conf --redis-cache-ttl duration Time-To-Live for redis cache (default 168h0m0s)",
      "title": "Redis cache"
    },
    {
      "location": "CACHE/#http-cache",
      "text": "To configure HTTP cache, use the following options: --http-cache-addr string The address of the http server for cacheID to layer sha mapping --http-cache-header stringArray Request header for http cache server. Format is \"--http-cache-header <header>:<value>\"",
      "title": "HTTP cache"
    },
    {
      "location": "CACHE/#explicit-commit-and-cache",
      "text": "By default, Makisu will cache each directive in a Dockerfile. To avoid committing and caching everything, the layer cache can be further optimized via explicit caching with the --commit=explicit flag. Dockerfile directives may then be manually cached using the #!COMMIT annotation: FROM node:8.1.3 ADD package.json package.json ADD pre-build.sh # A bunch of pre-install steps here. ... ... ... # A step to be cached. A single layer will be committed and cached here on top of base image. RUN npm install #!COMMIT ... ... ... # The last step of the last stage always commit by default, generating and caching another layer. ENTRYPOINT [\"/bin/bash\"] In this example, only 2 additional layers on top of base image will be generated and cached.",
      "title": "Explicit commit and cache"
    },
    {
      "location": "CONTRIBUTING/",
      "text": "Contributing To Makisu Issues Please feel free to submit new issues. Contributing Please follow standard fork-and-pull workflow. Fork the repo on GitHub Clone the project locally Commit changes to your own branch Push the change back to your fork Submit a Pull request. We will review and merge your change. Setup Most tests and scripts assumes the developer to have Docker installed locally. To install dependencies: $ make vendor To run unit tests: $ make unit-test To run integration tests: $ make integration",
      "title": "Contributing To Makisu"
    },
    {
      "location": "CONTRIBUTING/#contributing-to-makisu",
      "text": "",
      "title": "Contributing To Makisu"
    },
    {
      "location": "CONTRIBUTING/#issues",
      "text": "Please feel free to submit new issues.",
      "title": "Issues"
    },
    {
      "location": "CONTRIBUTING/#contributing",
      "text": "Please follow standard fork-and-pull workflow. Fork the repo on GitHub Clone the project locally Commit changes to your own branch Push the change back to your fork Submit a Pull request. We will review and merge your change.",
      "title": "Contributing"
    },
    {
      "location": "CONTRIBUTING/#setup",
      "text": "Most tests and scripts assumes the developer to have Docker installed locally. To install dependencies: $ make vendor To run unit tests: $ make unit-test To run integration tests: $ make integration",
      "title": "Setup"
    },
    {
      "location": "REGISTRY/",
      "text": "Registry configuration General info Makisu supports TLS and Basic Auth with Docker registry (Docker Hub, GCR, and private registries). By default, TLS is enabled and makisu uses a list of common root CA certs to authenticate registry. // Config contains Docker registry client configuration. type Config struct { Concurrency int `yaml:\"concurrency\"` Timeout time.Duration `yaml:\"timeout\"` Retries int `yaml:\"retries\"` PushRate float64 `yaml:\"push_rate\"` // If not specify, a default chunk size will be used. // Set it to -1 to turn off chunk upload. // NOTE: gcr does not support chunked upload. PushChunk int64 `yaml:\"push_chunk\"` Security security.Config{ TLS *httputil.TLSConfig `yaml:\"tls\"` BasicAuth *types.AuthConfig `yaml:\"basic\"` }`yaml:\"security\"` } Configs can be passed in through the --registry-config flag, either as filepath, or as a raw json blob : --registry-config='{\"gcr.io\": {\"uber-container-tools/*\": {\"push_chunk\": -1, \"security\": {\"basic\": {\"username\": \"_json_key\", \"password\": \"<escaped key here>\"}}}}}' Consider using the great tool yq to convert your yaml configuration into the blob that can be passed in. Examples For the convenience to work with all public Docker Hub repositories including library/.*, a default config is provided: index.docker.io: .*: security: tls: client: disabled: false // Docker Hub requires basic auth with empty username and password for all public repositories. basic: username: \"\" password: \"\" Example config for GCR: \"gcr.io\": \"uber-container-tools/*\": push_chunk: -1 security: basic: username: _json_key password: |- { <json here> } To configure your own registry endpoint, pass a custom configuration file to Makisu with --registry-config=${PATH_TO_CONFIG} .: [registry]: [repo]: security: tls: client: disabled: false cert: path: <path to cert> key: path: <path to key> passphrase path: <path to passphrase> ca: cert: path: <path to ca certs, appends to system certs. A list of common ca certs are used if empty> basic: username: <username> password: <password> Note: For the cert path, you can point to a directory containing your certificates. Makisu will then use all of the certs in that directory for TLS verification. Cred helper Makisu images (>= 0.1.8) contains ECR and GCR cred helper binaries. For ECR, you can export the following variables and you might need to export AWS_SDK_LOAD_CONFIG=true . If you encounter a certificate validation errors (ex: x509: certificate signed by unknown authority ) you might want to export the following variable SSL_CERT_DIR=/makisu-internal/certs/ . Example AWS ECR config: \"someawsregistry\": \"my-project/*\": push_chunk: -1 security: credsStore: ecr-login Example GCR config: \"gcr.io\": \"my-project/*\": push_chunk: -1 security: credsStore: gcr NB: You need to put your config files (ex: aws config/credentials file) inside the /makisu-internal/ dir (and use env variable to specify their locations) in order for the helpers to find and use them when building your images. Using another cred helper For now makisu handles ECR and GCR as lib instead of calling their binaries. If you want to use another docker credentials helper, add its binary in the directory /makisu-internal , with a name matching docker-credential-<cred-helper-name> , then in your configuration: \"example.com\": \"my-project/*\": security: credsStore: <cred-helper-name> Handling BLOB_UPLOAD_INVALID and BLOB_UPLOAD_UNKNOWN errors If you encounter these errors when pushing your image to a registry, try to use the push_chunk: -1 option (some registries, despite implementing registry v2 do not support chunked upload, ECR and GCR being one example).",
      "title": "Registry configuration"
    },
    {
      "location": "REGISTRY/#registry-configuration",
      "text": "",
      "title": "Registry configuration"
    },
    {
      "location": "REGISTRY/#general-info",
      "text": "Makisu supports TLS and Basic Auth with Docker registry (Docker Hub, GCR, and private registries). By default, TLS is enabled and makisu uses a list of common root CA certs to authenticate registry. // Config contains Docker registry client configuration. type Config struct { Concurrency int `yaml:\"concurrency\"` Timeout time.Duration `yaml:\"timeout\"` Retries int `yaml:\"retries\"` PushRate float64 `yaml:\"push_rate\"` // If not specify, a default chunk size will be used. // Set it to -1 to turn off chunk upload. // NOTE: gcr does not support chunked upload. PushChunk int64 `yaml:\"push_chunk\"` Security security.Config{ TLS *httputil.TLSConfig `yaml:\"tls\"` BasicAuth *types.AuthConfig `yaml:\"basic\"` }`yaml:\"security\"` } Configs can be passed in through the --registry-config flag, either as filepath, or as a raw json blob : --registry-config='{\"gcr.io\": {\"uber-container-tools/*\": {\"push_chunk\": -1, \"security\": {\"basic\": {\"username\": \"_json_key\", \"password\": \"<escaped key here>\"}}}}}' Consider using the great tool yq to convert your yaml configuration into the blob that can be passed in.",
      "title": "General info"
    },
    {
      "location": "REGISTRY/#examples",
      "text": "For the convenience to work with all public Docker Hub repositories including library/.*, a default config is provided: index.docker.io: .*: security: tls: client: disabled: false // Docker Hub requires basic auth with empty username and password for all public repositories. basic: username: \"\" password: \"\" Example config for GCR: \"gcr.io\": \"uber-container-tools/*\": push_chunk: -1 security: basic: username: _json_key password: |- { <json here> } To configure your own registry endpoint, pass a custom configuration file to Makisu with --registry-config=${PATH_TO_CONFIG} .: [registry]: [repo]: security: tls: client: disabled: false cert: path: <path to cert> key: path: <path to key> passphrase path: <path to passphrase> ca: cert: path: <path to ca certs, appends to system certs. A list of common ca certs are used if empty> basic: username: <username> password: <password> Note: For the cert path, you can point to a directory containing your certificates. Makisu will then use all of the certs in that directory for TLS verification.",
      "title": "Examples"
    },
    {
      "location": "REGISTRY/#cred-helper",
      "text": "Makisu images (>= 0.1.8) contains ECR and GCR cred helper binaries. For ECR, you can export the following variables and you might need to export AWS_SDK_LOAD_CONFIG=true . If you encounter a certificate validation errors (ex: x509: certificate signed by unknown authority ) you might want to export the following variable SSL_CERT_DIR=/makisu-internal/certs/ . Example AWS ECR config: \"someawsregistry\": \"my-project/*\": push_chunk: -1 security: credsStore: ecr-login Example GCR config: \"gcr.io\": \"my-project/*\": push_chunk: -1 security: credsStore: gcr NB: You need to put your config files (ex: aws config/credentials file) inside the /makisu-internal/ dir (and use env variable to specify their locations) in order for the helpers to find and use them when building your images.",
      "title": "Cred helper"
    },
    {
      "location": "REGISTRY/#using-another-cred-helper",
      "text": "For now makisu handles ECR and GCR as lib instead of calling their binaries. If you want to use another docker credentials helper, add its binary in the directory /makisu-internal , with a name matching docker-credential-<cred-helper-name> , then in your configuration: \"example.com\": \"my-project/*\": security: credsStore: <cred-helper-name>",
      "title": "Using another cred helper"
    },
    {
      "location": "REGISTRY/#handling-blob_upload_invalid-and-blob_upload_unknown-errors",
      "text": "If you encounter these errors when pushing your image to a registry, try to use the push_chunk: -1 option (some registries, despite implementing registry v2 do not support chunked upload, ECR and GCR being one example).",
      "title": "Handling BLOB_UPLOAD_INVALID and BLOB_UPLOAD_UNKNOWN errors"
    }
  ]
}
